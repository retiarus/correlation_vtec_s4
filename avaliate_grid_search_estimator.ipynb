{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from utils import MySet\n",
    "\n",
    "from utils import local_data\n",
    "from utils import window\n",
    "from utils import Scale, give_error\n",
    "from utils import generate_and_avaliate_model\n",
    "\n",
    "from utils import location_station, find_set_sunrise, find_set_sunset\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "latter_size = 14\n",
    "plt.rcParams['legend.fontsize'] = latter_size \n",
    "plt.rcParams['font.size'] = latter_size \n",
    "plt.rcParams['axes.labelsize'] = latter_size\n",
    "plt.rcParams['xtick.labelsize'] = latter_size\n",
    "plt.rcParams['ytick.labelsize'] = latter_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/sj2_analise_update.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vtec', 'vtec_dt', 'vtec_dt2', 'gvtec1', 'gvtec1_dt', 'gvtec2',\n",
       "       'gvtec2_dt', 'state_night', 'state_dawn', 'vm1', 'vd1', 'vm2', 'vd2',\n",
       "       'gvtec1_dt_lag_9', 'gvtec2_dt_lag_20', 'vtec_dt_lag_3', 's4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = MySet('original', ['vtec', 'vtec_dt', 'vtec_dt2', 'gvtec1', 'gvtec1_dt', 'gvtec2', 'gvtec2_dt'])\n",
    "tempo  = MySet('tempo', ['state_night', 'state_dawn'])\n",
    "mdv1 = MySet('mdv1', ['vm1', 'vd1'])\n",
    "mdv2 = MySet('mdv2', ['vm2', 'vd2'])\n",
    "lag = MySet('lag', ['gvtec1_dt_lag_9', 'gvtec2_dt_lag_20'])\n",
    "\n",
    "vtec = MySet('vtec', ['vtec'])\n",
    "vtec_dt = MySet('vtec_dt', ['vtec_dt'])\n",
    "vtec_dt2 = MySet('vtec_dt2', ['vtec_dt2'])\n",
    "gvtec1 = MySet('gvtec1', ['gvtec1'])\n",
    "gvtec1_dt = MySet('gvtec1_dt', ['gvtec1_dt'])\n",
    "gvtec2 = MySet('gvtec2', ['gvtec2'])\n",
    "gvtec2_dt = MySet('gvtec2_dt', ['gvtec2_dt'])\n",
    "state_night = MySet('state_night', ['state_night'])\n",
    "state_dawn = MySet('state_dawn', ['state_dawn'])\n",
    "vm1 = MySet('vm1', ['vm1'])\n",
    "vd1 = MySet('vd1', ['vd1'])\n",
    "vm2 = MySet('vm2', ['vm2'])\n",
    "vd2 = MySet('vd2', ['vd2'])\n",
    "gvtec1_dt_lag_9 = MySet('gvtec1_dt_lag_9', ['gvtec1_dt_lag_9'])\n",
    "gvtec2_dt_lag_20 = MySet('gvtec2_dt_lag_20', ['gvtec2_dt_lag_20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_test = vtec+tempo+lag+mdv1+mdv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_set = list(set_test.set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4320 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 49.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 66.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed: 101.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3265 tasks      | elapsed: 122.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 156.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4885 tasks      | elapsed: 192.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5816 tasks      | elapsed: 229.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6829 tasks      | elapsed: 269.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7922 tasks      | elapsed: 320.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9097 tasks      | elapsed: 359.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed: 416.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11689 tasks      | elapsed: 479.0min\n",
      "[Parallel(n_jobs=-1)]: Done 13106 tasks      | elapsed: 532.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14605 tasks      | elapsed: 589.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 650.8min\n",
      "[Parallel(n_jobs=-1)]: Done 17845 tasks      | elapsed: 721.9min\n",
      "[Parallel(n_jobs=-1)]: Done 19586 tasks      | elapsed: 795.5min\n",
      "[Parallel(n_jobs=-1)]: Done 21409 tasks      | elapsed: 870.8min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed: 954.7min\n",
      "[Parallel(n_jobs=-1)]: Done 25297 tasks      | elapsed: 1081.9min\n",
      "[Parallel(n_jobs=-1)]: Done 27362 tasks      | elapsed: 1220.4min\n",
      "[Parallel(n_jobs=-1)]: Done 29509 tasks      | elapsed: 1367.2min\n",
      "[Parallel(n_jobs=-1)]: Done 31736 tasks      | elapsed: 1507.0min\n",
      "[Parallel(n_jobs=-1)]: Done 34045 tasks      | elapsed: 1639.3min\n",
      "[Parallel(n_jobs=-1)]: Done 36434 tasks      | elapsed: 1800.8min\n",
      "[Parallel(n_jobs=-1)]: Done 38905 tasks      | elapsed: 1966.1min\n",
      "[Parallel(n_jobs=-1)]: Done 41456 tasks      | elapsed: 2109.8min\n",
      "[Parallel(n_jobs=-1)]: Done 43200 out of 43200 | elapsed: 2220.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('model', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impur...='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'model__n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'model__max_features': ['auto', 'sqrt'], 'model__max_depth': [10, 27, 44, 61, 78, 95, 112, 129, 146, 163, 180, None], 'model__min_samples_split': [2, 5, 10], 'model__min_samples_leaf': [1, 2, 4], 'model__bootstrap': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor\n",
    "\n",
    "# define parameters for grid_search\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 180, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'model__n_estimators': n_estimators,\n",
    "              'model__max_features': max_features,\n",
    "              'model__max_depth': max_depth,\n",
    "              'model__min_samples_split': min_samples_split,\n",
    "              'model__min_samples_leaf': min_samples_leaf,\n",
    "              'model__bootstrap': bootstrap}\n",
    "\n",
    "# select data\n",
    "X = df[instances_set].values\n",
    "y = df['s4'].values\n",
    "\n",
    "size = len(X)\n",
    "last_element = size - size//10\n",
    "\n",
    "X_train = X[0:last_element]\n",
    "y_train = y[0:last_element] \n",
    "       \n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('model', model()))\n",
    "pipeline = Pipeline(estimators)\n",
    "    \n",
    "clf = GridSearchCV(estimator=pipeline,\n",
    "                   param_grid=param_grid,\n",
    "                   cv=10,\n",
    "                   verbose=2,\n",
    "                   n_jobs=-1,\n",
    "                   scoring='neg_mean_squared_error')\n",
    "      \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'model__bootstrap': True, 'model__max_depth': 146, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 4, 'model__min_samples_split': 10, 'model__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = clf.best_estimator_.get_params()\n",
    "print(type(clf.best_params_))\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters_model = best_parameters['model'].get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=146,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=4, min_samples_split=10,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressor(**best_parameters['model'].get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/best_parameters_model_rf_complete_fase1.pkl\",\"wb\") as file:\n",
    "    pickle.dump(best_parameters_model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dscience)",
   "language": "python",
   "name": "dscience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
