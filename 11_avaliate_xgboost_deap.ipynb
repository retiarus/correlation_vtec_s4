{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pdb\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from evolutionary_search import EvolutionaryAlgorithmSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import recall_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from utils import MySet\n",
    "\n",
    "from utils import local_data\n",
    "from utils import window\n",
    "from utils import Scale, give_error\n",
    "from utils import generate_and_avaliate_model\n",
    "\n",
    "from utils import location_station, find_set_sunrise, find_set_sunset\n",
    "\n",
    "#%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "latter_size = 14\n",
    "plt.rcParams['legend.fontsize'] = latter_size \n",
    "plt.rcParams['font.size'] = latter_size \n",
    "plt.rcParams['axes.labelsize'] = latter_size\n",
    "plt.rcParams['xtick.labelsize'] = latter_size\n",
    "plt.rcParams['ytick.labelsize'] = latter_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/sj2_analise_update2_drop.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vtec', 'vtec_dt', 'vtec_dt2', 'gvtec1', 'gvtec1_dt', 'gvtec2',\n",
       "       'gvtec2_dt', 'gvtec3', 'gvtec3_dt', 's4', 'state_night', 'state_dawn',\n",
       "       'vm1', 'vd1', 'vm2', 'vd2', 'gvtec1_dt_lag_9', 'gvtec2_dt_lag_20',\n",
       "       'vtec_dt_lag_3', 'vtec_i/vtec_i-1', 'roti_3', 'roti_5', 'roti_7',\n",
       "       'roti_9', 'roti_11', 'roti_13', 'gvtec1/gvtec2', 'gvtec1_dt/gvtec2_dt',\n",
       "       'doy', 'ut', 'discretize_s4', 'discretize_s4_02', 'discretize_s4_03',\n",
       "       'discretize_s4_04', 'discretize_s4_05', 'discretize_s4_06',\n",
       "       'discretize_s4_07'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = MySet('original', ['vtec', 'vtec_dt', 'vtec_dt2', 'gvtec1', 'gvtec1_dt', 'gvtec2',\n",
    "       'gvtec2_dt', 'gvtec3', 'gvtec3_dt', 'state_night', 'state_dawn', 'vm1', 'vd1', 'vm2', 'vd2', 'gvtec1_dt_lag_9',\n",
    "       'gvtec2_dt_lag_20', 'vtec_dt_lag_3', 'vtec_i/vtec_i-1', 'roti_3',\n",
    "       'roti_5', 'roti_7', 'roti_9', 'roti_11', 'roti_13', 'gvtec1/gvtec2',\n",
    "       'gvtec1_dt/gvtec2_dt', 'doy', 'ut'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=100, stop=3000, num=15)]\n",
    "learning_rate = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "max_depth = [int(x) for x in np.linspace(5, 20, num=10)]\n",
    "subsample = [0.3, 0.5, 0.75, 1.0]\n",
    "colsample_bytree = [.3, .5, .7, .9, 1.0]\n",
    "colsample_bylevel = [.3, .5, .7, .9, 1.0]\n",
    "min_child_weight = [i for i in range(0, 20)]\n",
    "gamma = [.3, .5, .7, .9, 1.0]\n",
    "num_class = 7,\n",
    "\n",
    "param_grid = {'model__n_estimators': n_estimators,\n",
    "              'model__max_depth': max_depth,\n",
    "              'model__learning_rate': learning_rate,\n",
    "              'model__max_depth': max_depth,\n",
    "              'model__subsample': subsample,\n",
    "              'model__colsample_bytree': colsample_bytree,\n",
    "              'model__colsample_bylevel': colsample_bylevel,\n",
    "              'model__min_child_weight': min_child_weight,\n",
    "              'model__gamma': gamma,\n",
    "              'model__num_class': [7,],\n",
    "              'model__objective': [\"multi:softmax\",],\n",
    "              'model__metric': [\"mlogloss\",]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data\n",
    "X = df[list(original.set)].values\n",
    "y = df['discretize_s4'].values\n",
    "\n",
    "recall_inbalanced_score = make_scorer(recall_score, average='macro')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)\n",
    "       \n",
    "# suffle the train data\n",
    "order = np.random.permutation(len(X_train))\n",
    "X_train = np.array([X_train[i] for i in order])\n",
    "y_train = np.array([y_train[i] for i in order])\n",
    "       \n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('model', XGBClassifier()))\n",
    "pipeline = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = EvolutionaryAlgorithmSearchCV(estimator=pipeline,\n",
    "                                    params=param_grid,\n",
    "                                    scoring=recall_inbalanced_score,\n",
    "                                    cv=StratifiedKFold(n_splits=10),\n",
    "                                    verbose=1,\n",
    "                                    population_size=500,\n",
    "                                    gene_mutation_prob=0.10,\n",
    "                                    gene_crossover_prob=0.5,\n",
    "                                    tournament_size=3,\n",
    "                                    generations_number=100,\n",
    "                                    n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types [1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1] and maxint [14, 9, 8, 3, 4, 4, 19, 4, 0, 0, 0] detected\n",
      "--- Evolve in 13500000 possible combinations ---\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = GridSearchCV(estimator=pipeline,\n",
    "#                   param_grid=param_grid,\n",
    "#                   cv=StratifiedKFold(n_splits=10),\n",
    "#                   verbose=2,\n",
    "#                   n_jobs=-1,\n",
    "#                   scoring=recall_inbalanced_score)\n",
    "      \n",
    "clf.fit(X_train, y_train)\n",
    "best_parameters_estimator = clf.best_estimator_.get_params()\n",
    "best_parameters_model = best_parameters_estimator['model'].get_params()\n",
    "\n",
    "with open('./data/xgboost_search_all_parameters.txt', 'w') as file:\n",
    "    file.write(str(best_parameters_model))\n",
    "    file.write(json.dumps(best_parameters_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dscience)",
   "language": "python",
   "name": "dscience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
